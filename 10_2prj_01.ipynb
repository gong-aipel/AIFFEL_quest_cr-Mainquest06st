{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBFmed9c4xHH+Y5NeT+6hZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jong104b-kr/AIFFEL_quest_cr/blob/master/10_2prj_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X24OhvUukaK0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 문제1-1. 이미지에 나온 VGG16 모델을 구현하세요.\n",
        "# 참고 코드\n",
        "\n",
        "input_layer=tf.keras.layers.Input(shape=(256, 256, 3))\n",
        "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(input_layer)\n",
        "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(256, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(256, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Flatten()(x)\n",
        "x=tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x=tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "out_layer=tf.keras.layers.Dense(1, activation='Softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_layer], outputs=[out_layer])\n",
        "model.summary()\n",
        "\n",
        "loss_function=tf.keras.losses.binary_crossentropy\n",
        "optimize=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "metric=tf.keras.metrics.binary_accuracy\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimize,\n",
        "              metrics=[metric])\n",
        "\n",
        "# callbacks_list= [tf.keras.callbacks.TensorBoard(log_dir='log_dir', histogram_freq=1)]\n",
        "# callback 함수를 활용하고 싶다면 추가해서 학습하는 데에 활용해 보세요.\n",
        "\n",
        "history = model.fit(\n",
        "      train_data_gen,\n",
        "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_data_gen,\n",
        "      # callbacks=callbacks_list,\n",
        "      validation_freq=1)\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 문제 1-2. hyperparameter 설정\n",
        "# parameter Initialization\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "# 문제 1-2. 데이터 generator 생성\n",
        "# Training data generator\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=0.3,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     zoom_range=0.1,\n",
        "                                     horizontal_flip=False,\n",
        "                                     vertical_flip=True)\n",
        "\n",
        "# 문제 1-2. 모델 구현\n",
        "# 참고 코드\n",
        "\n",
        "input_layer=tf.keras.layers.Input(shape=(256, 256, 3))\n",
        "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(input_layer)\n",
        "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(256, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(256, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.Conv2D(512, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "x=tf.keras.layers.Flatten()(x)\n",
        "x=tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x=tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "out_layer=tf.keras.layers.Dense(1, activation='Softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_layer], outputs=[out_layer])\n",
        "model.summary()\n",
        "\n",
        "# 문제 1-2. loss function, optimizer, metric 설정 및 모델 컴파일\n",
        "loss_function=tf.keras.losses.binary_crossentropy\n",
        "optimize=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "metric=tf.keras.metrics.binary_accuracy\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimize,\n",
        "              metrics=[metric])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "      train_data_gen,\n",
        "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_data_gen,\n",
        "      # callbacks=callbacks_list,\n",
        "      validation_freq=1)\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ]
}